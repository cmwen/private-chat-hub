# UX Design v2: Key User Flows

**Document Version:** 1.0  
**Purpose:** Map critical user journeys for v2 features  
**Scope:** End-to-end flows for each phase

---

## Phase 1: Tool Calling Flows

### Flow 1.1: User Asks Question That Requires Web Search

```
User â†’ "What's the latest news about AI?"
         â†“
Model detects question needs current info
         â†“
AI decides to use Web Search tool
         â†“
UI shows: ğŸ” "Searching web..." (spinner, 0.0-3.0s)
         â†“
Web search API called (async)
         â†“
Results arrive as stream
         â†“
UI shows: ğŸ” Web Search Results
         - Result 1: Title + snippet + link
         - Result 2: Title + snippet + link
         - Result 3: Title + snippet + link
         [See 3 more results] (collapsed)
         â†“
Model incorporates results into response
         â†“
UI shows: Model's answer based on search results
         â†“
User can:
- Read full response
- View search results (collapse/expand)
- Open result links
- Copy response
- Regenerate without search
```

**Time: 3-5s total (search + model response)**

---

### Flow 1.2: Web Search Configuration

```
User â†’ Settings â†’ Tools & Features
         â†“
Sees: Web Search toggle [ON]
      Status: Connected âœ“
      Monthly quota: 85/100
      [Configure] [Test Search]
         â†“
Tap [Configure]
         â†“
Dialog shows:
- API Key field (encrypted)
- Search region/language
- Result limit (10/25/50)
- Safe search toggle
         â†“
User updates settings
         â†“
Tap [Save]
         â†“
Settings saved locally
Connection verified âœ“
         â†“
Return to chat
         â†“
Web search ready to use
```

**Time: 2-3 min (one-time setup)**

---

### Flow 1.3: Tool Error Recovery

```
User â†’ Asks question requiring web search
         â†“
ğŸ” "Searching web..." (starts)
         â†“
[After 30s] Connection timeout
         â†“
UI shows error:
âŒ "Web search failed: Connection timeout"
         â†“
User sees options:
[â†» Retry search]
[Continue without search]
[Go to settings]
         â†“
Path A: User taps [â†» Retry]
         â†“
Search attempts again
         â†“
[Success] â†’ Show results
[Failure again] â†’ Show error + fallback options
         â†“
Path B: User taps [Continue without search]
         â†“
Model generates response without web search
         â†“
"Based on my training data..."
         â†“
Path C: User taps [Go to settings]
         â†“
Opens tool configuration
         â†“
User checks API key, updates if needed
         â†“
Returns to chat, tries again
```

**Error recovery time: 30-60s total**

---

## Phase 2: Model Comparison Flows

### Flow 2.1: Start Comparison Mode

```
User â†’ Chat screen with single model (llama3.2)
         â†“
Tap model selector dropdown
         â†“
Menu shows:
[âœ“] Single Model
[  ] Compare Models â†’ [Start Comparison]
         â†“
Tap "Start Comparison"
         â†“
Modal dialog appears:
"Select 2-4 Models to Compare"
â˜‘ llama3.2 (4.1GB, Fast)
â˜‘ mistral (4.2GB, Balanced)
â˜ neural-chat (3.8GB, Creative)
â˜ qwen2.5 (6.2GB, Detail)
         â†“
User selects 2-4 models (default: select first 2)
         â†“
Tap [Start Comparing]
         â†“
UI transforms to side-by-side comparison view
         â†“
Chat history cleared
Next message will go to all selected models
         â†“
User types message
         â†“
"Explain binary search"
         â†“
Tap [Send]
```

**Setup time: 10-15 seconds**

---

### Flow 2.2: Compare Two Models

```
User â†’ Side-by-side comparison mode (2 models)
         â†“
User types: "Explain binary search"
         â†“
Press Send
         â†“
Messages sent to both models simultaneously
         â†“
UI shows:
llama3.2    |    mistral
Loading...  |    Loading...
â³ 1.2s     |    â³ 0.9s
         â†“
Model responses stream in
         â†“
llama3.2 responds first (at 2.1s)
Response appears in left column
         â†“
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] Progress shown
         â†“
mistral responds (at 1.9s total)
Response appears in right column
         â†“
Both columns show full responses
         â†“
User can:
- Read both responses side-by-side
- Scroll independently
- Tap [ğŸ˜Š Good] to rate
- Long-press to copy, share, etc.
- Swipe left to see metrics (time, tokens)
- Tap [See diff] to highlight unique parts
         â†“
User sends another message
         â†“
Both models respond again
```

**Response time: 2-3 seconds (parallelized)**

---

### Flow 2.3: Compare Four Models (Tabbed)

```
User â†’ Selects 4 models for comparison
         â†“
UI shows: Tabbed view
[llama3.2] [mistral] [neural] [qwen2.5]
         â†“
User types: "Explain binary search"
         â†“
Send message
         â†“
All 4 models receive message simultaneously
         â†“
UI shows loading state:
llama3.2 â³ 1.2s
mistral  â³ 0.9s
neural   â³ 1.5s
qwen2.5  â³ 1.3s
         â†“
Responses stream in (in any order)
         â†“
Tab shows: "llama3.2 (2.1s)" [Completed]
         â†“
User taps tab to see response
         â†“
Can switch between tabs to compare
         â†“
Swipe horizontally to move between tabs
         â†“
Metrics shown: Time, tokens, quality score
         â†“
User can:
- View each response independently
- Quick-switch tabs
- See performance metrics
- Copy/share individual responses
```

**Response time: 3-4 seconds (longest model)**

---

### Flow 2.4: Response Diff View

```
User â†’ In comparison mode with responses
         â†“
Tap [See Diff] on responses
         â†“
Diff view appears showing:
         â†“
[Common text in gray]
"Here's how binary search works..."
         â†“
[Unique to mistral in green ğŸŸ¢]
"The key insight is that..."
         â†“
[Common text in gray]
"This algorithm is efficient"
         â†“
[Unique to llama3.2 in red ğŸ”´]
"Time complexity: O(log n)"
         â†“
User can:
- Scroll through highlighting
- Tap to expand context
- Copy just the diff
- Export as markdown
- Share comparison
         â†“
Tap [Back] to see full responses again
```

**Diff generation time: <500ms**

---

## Phase 3: Native Integration Flows

### Flow 3.1: Receive Share From Another App

```
User â†’ In Chrome browser, finds article
         â†“
Reads article, wants AI analysis
         â†“
Long-press article â†’ Share menu
         â†“
Sees: Private Chat Hub icon in share sheet
         â†“
Taps: Private Chat Hub
         â†“
App opens/resumes
         â†“
Chat screen shows:
[Shared from Chrome - Article Text]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ "Researchers Announce..."       â”‚
â”‚ [Remove]                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Message input pre-populated:
"[Article text here]"
         â†“
User can:
- Edit the shared text
- Add their own question
- Clear shared content
- Send to model
         â†“
User types additional prompt:
"Summarize this and highlight key points"
         â†“
Send
         â†“
Model processes both context + prompt
         â†“
Response: "Summary: ... Key points: ..."
```

**Time: <2 seconds to receive + show**

---

### Flow 3.2: Send Message to Another App

```
User â†’ Has AI response in chat
         â†“
Long-press response message
         â†“
Context menu appears:
[Copy] [Share] [Regenerate] [More]
         â†“
Tap [Share]
         â†“
Share dialog shows:

Format:
â—‹ Plain text
â— Markdown (with formatting)
â—‹ HTML

Preview:
"User: Explain binary search"
"AI: Binary search is..."

[Share to...]
[Gmail] [Messages] [Docs] [Notion] [More]
         â†“
User taps [Gmail]
         â†“
Gmail opens with message in compose
```

**Time: 10-20 seconds (open share â†’ Gmail)**

---

### Flow 3.3: Text-to-Speech Response

```
User â†’ AI gives response
         â†“
Response shows with TTS button:
[â–¶ Listen] [â¸ Pause] [1.0xâ–¼] [âš™ï¸]
         â†“
Tap [â–¶ Listen]
         â†“
Audio starts (if already cached) or generates
Possible states:
- <500ms: Already generated, plays immediately
- 1-3s: Generate TTS audio, then play
         â†“
Response highlights current text being read
         â†“
Progress bar shows: [â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 20%
         â†“
User can:
- Swipe progress bar to seek
- Tap [â¸ Pause] to pause
- Change speed with [1.0xâ–¼]
- Continue in background (app backgrounded)
- Return to app, resume from where paused
         â†“
TTS ends
         â†“
Button returns to [â–¶ Listen] (restart)
```

**Time: <5 seconds to start audio**

---

### Flow 3.4: Configure Text-to-Speech

```
User â†’ Settings â†’ Text-to-Speech
         â†“
Sees:
Enable TTS                    [Toggle: ON]
Voice: [System Default â–¼]
Speed: [0.8---[â—]---2.0]
Auto-play messages           [Toggle: OFF]
Continue when backgrounded   [Toggle: ON]
         â†“
User wants to change voice
         â†“
Tap [System Default â–¼]
         â†“
Menu shows available voices:
â—‹ System Default (current)
â—‹ Female Voice 1
â—‹ Male Voice 1
â—‹ Custom Voice (if downloaded)
         â†“
Select different voice
         â†“
Tap [Preview]
         â†“
Generates and plays sample:
"Here's how binary search works..."
         â†“
User adjusts speed slider
         â†“
Tap [Preview] again to hear with new speed
         â†“
Tap [Save]
         â†“
Settings saved
         â†“
TTS ready with new voice + speed
```

**Time: 2-3 minutes (one-time setup)**

---

## Phase 4: Long-Running Tasks Flows

### Flow 4.1: Start Long-Running Task

```
User â†’ Chat screen
         â†“
Wants to do complex task:
"Research latest AI papers, analyze them, 
create 5-page summary"
         â†“
Model detects this is multi-step task
         â†“
Suggests:
"This is a complex task (5 steps, ~10 min).
Create a task to track progress?"
         â†“
User taps [Create Task]
         â†“
Task created with steps:
1. Search for papers
2. Download papers
3. Analyze content
4. Compile summary
5. Final review
         â†“
UI shows: TaskProgressCard
ğŸ¯ Research Task
[â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0%
Step 1: Search for papers (pending)
         â†“
Execution starts
         â†“
Step 1 running:
[â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 20%
â³ Searching for papers (45s elapsed)
         â†“
Step 1 completes:
âœ“ Found 12 papers on arXiv
         â†“
Step 2 starts:
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 40%
â³ Downloading papers (38s elapsed)
```

**Estimated total time: 8-12 minutes**

---

### Flow 4.2: Monitor Background Task

```
User â†’ Task is running (Step 3/5 at 65%)
         â†“
User needs to do something else
         â†“
Closes app or navigates elsewhere
         â†“
Task continues in background
         â†“
Notification appears (Android notification center):
ğŸ¯ Research Task
Processing: Step 3/5 (65%)
~1m 30s remaining
[â¸] [â¹] [â†’ View]
         â†“
User can:
- Tap [â†’ View]: Return to task details
- Tap [â¸]: Pause task
- Tap [â¹]: Cancel task
- Ignore: Task continues in background
         â†“
Option A: User taps [â†’ View]
         â†“
App opens/resumes
Returns to TaskProgressCard
Shows current step: Step 3/5 (65%)
         â†“
User watches progress, then navigates away again
         â†“
Task continues in background
         â†“
Notification updates: Step 4/5 (75%), 1m remaining
         â†“
[Notification] Task complete! (click to view results)
         â†“
Option B: User ignores notifications
         â†“
Task completes silently in background
         â†“
When user returns to app, sees completion in task list
```

**Background execution: 8-12 minutes**

---

### Flow 4.3: Task Completes Successfully

```
Task: Research AI Papers (Step 5/5)
         â†“
Final review step completes
         â†“
âœ“ All steps completed
         â†“
TaskProgressCard updates:
ğŸ¯ Research Task                [âœ“ Done]
"Research AI papers and summarize"
Completed in: 10m 32s
         â†“
Shows breakdown:
âœ“ Step 1: Search papers (45s) â†’ Found 12
âœ“ Step 2: Download (38s) â†’ 2.3GB
âœ“ Step 3: Analyze (5m 22s) â†’ 1,245 pages
âœ“ Step 4: Compile (1m 48s) â†’ 5 pages
âœ“ Step 5: Review (12s) â†’ Verified
         â†“
Result content shows:
Key Findings:
â€¢ Transformers remain dominant
â€¢ Multi-modal models advancing
â€¢ Efficiency improvements critical
         â†“
User can:
[ğŸ’¾ Save] [ğŸ“¤ Share] [ğŸ”„ Refine] [â• New]
         â†“
Tap [Share]
         â†“
Export as markdown/PDF and share
         â†“
Tap [Refine]
         â†“
"What would you like to refine?"
         â†“
User asks follow-up question
         â†“
New task created based on previous results
```

**Task completion time: 8-12 minutes**

---

### Flow 4.4: Task Error & Recovery

```
Task: Code Generation Sprint (Step 2/8)
         â†“
Step 2 executes
         â†“
API rate limit exceeded
         â†“
âŒ Step 2 failed: "API quota exceeded"
         â†“
Task pauses automatically
         â†“
TaskProgressCard shows:
ğŸ¯ Code Generation Sprint     âš ï¸ Paused
Step 2/8: Generate functions
Status: Failed - API rate limit exceeded
[â–¶ Resume] [Skip step] [Cancel] [Logs]
         â†“
Notification: Task paused - API error
         â†“
User has options:
         â†“
Path A: Wait for rate limit to reset
         â†“
[â–¶ Resume] â†’ Task tries step 2 again
         â†“
Success â†’ Continues to Step 3
         â†“
Path B: Skip problematic step
         â†“
[Skip step] â†’ Task moves to Step 3
         â†“
Continues without Step 2 result
         â†“
Path C: Cancel entire task
         â†“
[Cancel] â†’ Task stops
         â†“
Results saved so far
Can restart later
         â†“
Path D: View logs
         â†“
[Logs] â†’ Shows detailed error
Can diagnose and retry with different settings
```

**Error recovery: 5-30 seconds (depending on fix)**

---

### Flow 4.5: Thinking Model Response

```
User â†’ Sends question to thinking model
         â†“
"How would you approach this algorithm problem?"
         â†“
Send to llama3.2-thinking
         â†“
Model processes (extended thinking)
         â†“
Thinking phase: Internal reasoning (2-5 min)
No UI updates (background)
         â†“
Response ready
         â†“
ThinkingModelDisplay shows:
ğŸ¤– llama3.2-thinking
[ğŸ”„ Show thinking process]
Thinking tokens: 2,450
Response tokens: 320
Reading fee: 1.5x (thinking premium)
         â†“
User taps [ğŸ”„ Show thinking]
         â†“
Expanded view shows:
"First, let me understand this problem..."
"The key insight is..."
"Therefore, the approach should be..."
[âŠ— Collapse]
         â†“
Final Answer:
"To approach this problem, you should..."
         â†“
User can:
- Copy thinking
- Copy response
- Export thinking process
- Use in task
```

**Thinking time: 2-5 minutes**

---

## Phase 5: MCP Integration Flows

### Flow 5.1: Connect MCP Server

```
User â†’ Settings â†’ MCP Servers
         â†“
Sees: "Connected Servers: 0"
         â†“
Taps [â• Add MCP Server]
         â†“
Dialog shows options:
â—‹ Auto-discover (local network)
â—‹ Manual connection (host + port)
         â†“
User selects [Manual connection]
         â†“
Form shows:
Server Name: [_________________]
Host: [localhost]
Port: [3000]
         â†“
User enters:
Server Name: "Code Tools"
Host: "localhost"
Port: "3000"
         â†“
Tap [Connect]
         â†“
Connection attempt:
â³ Connecting to localhost:3000...
         â†“
ğŸŸ¢ Connected!
Fetching tools...
         â†“
ğŸ”Œ Code Tools
Status: Connected âœ“
Tools: 12 available
         â†“
User can:
[View Tools] [Disconnect] [Settings]
         â†“
Server now available in chat
```

**Connection time: 2-5 seconds**

---

### Flow 5.2: Discover Tools

```
User â†’ MCP Servers screen
         â†“
ğŸ”Œ Code Tools (Connected)
         â†“
Taps [View Tools]
         â†“
MCPToolLibrary screen shows:
Code Tools (12 total)
[Search...]
         â†“
All tools listed:
â˜‘ Git Status
   Get current repository status
   Status: Auto-allow
         â†“
â˜‘ Search Codebase
   Find code by pattern
   Status: Auto-allow
         â†“
âš ï¸ Execute Script
   Run shell scripts (SENSITIVE)
   Status: Requires confirmation
   [Configure permissions]
         â†“
User can:
- Toggle auto-allow per tool
- Configure permissions
- View tool parameters
- Search tools
         â†“
User sets Execute Script to "Deny"
         â†“
Saved
         â†“
Return to chat
         â†“
Tools ready to use
```

**Configuration time: 2-3 minutes (one-time)**

---

### Flow 5.3: Use MCP Tool in Chat

```
User â†’ Chat screen (MCP server connected)
         â†“
User asks: "Show me the binary_search function"
         â†“
Model detects this requires code search
         â†“
Model invokes MCP tool: "Search Codebase"
         â†“
Parameters: { query: "binary_search" }
         â†“
UI shows:
ğŸ”Œ Code Tools: Using "Search Codebase"
   Searching for: "binary_search"
   Found 3 matches (0.8s)
         â†“
Tool results display:
â”Œâ”€ src/algorithms/search.py (Line 42)
â”‚ def binary_search(arr, target):
â”‚   left = 0
â”‚   right = len(arr) - 1
â”‚   while left <= right:
â”‚     mid = (left + right) // 2
â”‚     if arr[mid] == target:
â”‚       return mid
â”‚ [View] [Copy] [Share]
â”‚
â”œâ”€ tests/test_search.py (Line 156)
â”‚ ...
â”‚
â””â”€ docs/examples.md (Line 42)
   ...
         â†“
Model response uses results:
"I found the binary_search function in your codebase
at src/algorithms/search.py, line 42. Here's the
implementation and how it works..."
         â†“
User can:
- View each result
- Copy code snippets
- Share files
- Send follow-up questions using code context
```

**Tool invocation time: <2 seconds**

---

## Summary: v2 User Journey Complexity

| Feature | Setup | Per-Use | Error Recovery |
|---------|-------|---------|-----------------|
| Tool Calling | 2-3 min | <5 sec | 30-60 sec |
| Comparison | 10-15 sec | 2-3 sec | 5-10 sec |
| Native Share | <2 sec | <5 sec | Immediate |
| TTS | 2-3 min | <5 sec | Immediate |
| Tasks | Automatic | 1-2 sec | 5-30 sec |
| MCP | 2-5 sec | <2 sec | 5-10 sec |

**Total setup time for v2 features: ~10-15 minutes (one-time)**

**Regular usage: Seamless, <5 seconds per feature**

